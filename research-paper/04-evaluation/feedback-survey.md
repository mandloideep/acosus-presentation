# User Feedback Survey Documentation

## Survey Purpose

The Qualtrics feedback survey serves as a primary evaluation instrument for assessing the AI counseling system's effectiveness in supporting transfer students. The survey addresses four key objectives:

1. **Assess User Experience** - Evaluate overall satisfaction and interaction quality with the AI counseling system
2. **Gather Usability Feedback** - Identify ease of use, learnability, and interface design effectiveness
3. **Evaluate System Usefulness** - Measure perceived value in academic planning and transfer preparation
4. **Identify Improvement Areas** - Collect actionable feedback for system enhancement

---

## Question Categories

### 1. Perceived Usefulness (Q1-Q6)
Questions adapted from the Technology Acceptance Model (TAM) measuring how users perceive the system's utility in accomplishing academic planning tasks.

### 2. Perceived Ease of Use (Q7-Q12)
TAM-derived questions assessing the system's learnability, flexibility, and overall ease of interaction.

### 3. System Understanding & Input (Q13-Q15)
Questions evaluating how well the system captures user needs and the intuitiveness of the data input process.

### 4. Interface & Technical Issues (Q16-Q18)
Mixed-format questions identifying specific usability problems and technical difficulties encountered.

### 5. Prediction Accuracy & Relevance (Q19-Q22)
Questions assessing the quality of the system's academic success predictions and recommendation relevance.

### 6. Feature Feedback (Q23-Q24)
Open-ended questions capturing the most valuable features and missing capabilities.

### 7. Future Use & Recommendation (Q25-Q26)
Net Promoter Score (NPS) style questions measuring likelihood of continued use and peer recommendation.

### 8. Accessibility & Device Usage (Q27-Q29)
Questions evaluating cross-device compatibility and accessibility compliance.

### 9. Improvement Suggestions (Q30-Q33)
Open-ended questions gathering personalization preferences and redesign ideas.

---

## Survey Questions Table

| ID | Question Text | Response Type | Category |
|----|---------------|---------------|----------|
| Q1 | Using this AI counseling system in my academic planning enables me to accomplish tasks more quickly than other advising methods. | 5-point Likert (Strongly disagree → Strongly agree) | Perceived Usefulness |
| Q2 | Using this AI counseling system improves my academic planning performance. | 5-point Likert (Strongly disagree → Strongly agree) | Perceived Usefulness |
| Q3 | Using this AI counseling system in my academic planning increases my productivity. | 5-point Likert (Strongly disagree → Strongly agree) | Perceived Usefulness |
| Q4 | Using this AI counseling system enhances my effectiveness in transfer planning. | 5-point Likert (Strongly disagree → Strongly agree) | Perceived Usefulness |
| Q5 | Using this AI counseling system makes it easier to plan my academic path. | 5-point Likert (Strongly disagree → Strongly agree) | Perceived Usefulness |
| Q6 | I have found this AI counseling system useful for my transfer journey. | 5-point Likert (Strongly disagree → Strongly agree) | Perceived Usefulness |
| Q7 | Learning to operate this AI counseling system was easy for me. | 5-point Likert (Strongly disagree → Strongly agree) | Perceived Ease of Use |
| Q8 | I found it easy to get this AI counseling system to do what I want it to do. | 5-point Likert (Strongly disagree → Strongly agree) | Perceived Ease of Use |
| Q9 | My interaction with this AI counseling system has been clear and understandable. | 5-point Likert (Strongly disagree → Strongly agree) | Perceived Ease of Use |
| Q10 | I found this AI counseling system to be flexible to interact with. | 5-point Likert (Strongly disagree → Strongly agree) | Perceived Ease of Use |
| Q11 | It was easy for me to become skillful at using this AI counseling system. | 5-point Likert (Strongly disagree → Strongly agree) | Perceived Ease of Use |
| Q12 | I found this AI counseling system easy to use. | 5-point Likert (Strongly disagree → Strongly agree) | Perceived Ease of Use |
| Q13 | The AI counseling system accurately understood my specific needs as a transfer student. | 5-point Likert (Strongly disagree → Strongly agree) | System Understanding |
| Q14 | The process of inputting my information into the system was straightforward. | 5-point Likert (Strongly disagree → Strongly agree) | System Understanding |
| Q15 | The system interface was intuitive and easy to navigate. | 5-point Likert (Strongly disagree → Strongly agree) | Interface Design |
| Q16 | What specific elements of the interface were difficult to navigate or understand? | Open-Ended | Interface Design |
| Q17 | Did you experience any technical issues while using the system? | Single Choice (Yes / Maybe / No) | Technical Issues |
| Q18 | What technical issue you faced while using this system? | Open-Ended | Technical Issues |
| Q19 | How accurate did you find the system's assessment of your academic success factors? | 5-point Likert (Not accurate at all → Extremely accurate) | Prediction Accuracy |
| Q20 | Did the success probability estimates align with your own assessment of your academic situation? | 5-point Likert (Not at all aligned → Perfectly aligned) | Prediction Accuracy |
| Q21 | How relevant were the recommendations provided by the system to your specific situation? | 5-point Likert (Not relevant at all → Extremely relevant) | Recommendation Quality |
| Q22 | How actionable were the recommendations provided? | 5-point Likert (Not actionable at all → Easily actionable) | Recommendation Quality |
| Q23 | What was the most helpful feature of the system? | Open-Ended | Feature Feedback |
| Q24 | What feature or capability was missing that would have improved your experience? | Open-Ended | Feature Feedback |
| Q25 | How likely are you to continue using this system for academic planning? | 5-point Likert (Extremely unlikely → Extremely likely) | Future Use Intent |
| Q26 | How likely are you to recommend this system to other transfer students? | 5-point Likert (Extremely unlikely → Extremely likely) | Recommendation Intent |
| Q27 | What devices did you primarily use to access the system? (Select all that apply) | Multiple Choice (Multi-select) | Device Usage |
| Q28 | Did you encounter any accessibility issues while using the system? | 5-point Likert (Definitely not → Definitely yes) | Accessibility |
| Q29 | Can you specify what accessibility issue was there in the system? | Open-Ended | Accessibility |
| Q30 | What additional features would make this system more valuable to transfer students? | Open-Ended | Improvement Suggestions |
| Q31 | Would you prefer a system that provides more standardized advice or one that's more personalized? | 7-point Likert (Highly standardized → Highly personalized) | Personalization Preference |
| Q32 | If you could redesign one aspect of the system, what would it be? | Open-Ended | Improvement Suggestions |
| Q33 | Please provide any additional feedback or suggestions that could help improve the system for future students. | Open-Ended | General Feedback |

---

## Evaluation Framework

### Theoretical Foundation

The survey instrument is grounded in the **Technology Acceptance Model (TAM)** framework, which posits that perceived usefulness and perceived ease of use are fundamental determinants of technology adoption. Questions Q1-Q12 directly map to TAM constructs.

### Construct Mapping

| Construct | Questions | Measurement Approach |
|-----------|-----------|---------------------|
| Perceived Usefulness (PU) | Q1-Q6 | 6-item composite score |
| Perceived Ease of Use (PEOU) | Q7-Q12 | 6-item composite score |
| System Quality | Q13-Q15, Q19-Q22 | Domain-specific assessment |
| Behavioral Intention | Q25-Q26 | Future use/recommendation intent |

---

## Analysis Plan

### Quantitative Metrics

#### Descriptive Statistics
- **Likert Scale Averages**: Calculate mean scores for each question and construct
- **Standard Deviation**: Measure response variability
- **Completion Rates**: Track survey completion and individual question response rates

#### Composite Scores
- **Perceived Usefulness Score**: Mean of Q1-Q6 (range: 1-5)
- **Perceived Ease of Use Score**: Mean of Q7-Q12 (range: 1-5)
- **Prediction Quality Score**: Mean of Q19-Q22 (range: 1-5)
- **Net Promoter Score (NPS)**: Derived from Q26 using standard NPS calculation

#### Reliability Analysis
- **Cronbach's Alpha**: Assess internal consistency for PU and PEOU constructs
- **Item-Total Correlations**: Identify potentially problematic items

#### Distribution Analysis
- Response distribution visualization for each Likert item
- Identification of ceiling/floor effects
- Cross-tabulation by demographic factors (if collected)

### Qualitative Analysis

#### Thematic Coding Approach
Open-ended responses (Q16, Q18, Q23, Q24, Q29, Q30, Q32, Q33) will be analyzed using:

1. **Initial Coding**: Line-by-line review to identify discrete concepts
2. **Focused Coding**: Group initial codes into broader themes
3. **Theme Development**: Synthesize themes into actionable categories

#### Expected Theme Categories
- Interface/Navigation Issues
- Technical Problems
- Feature Requests
- Positive System Attributes
- Personalization Needs
- Accessibility Concerns

#### Coding Reliability
- Dual-coder approach for inter-rater reliability
- Cohen's Kappa calculation for agreement measure

### Reporting Outputs

1. **Summary Statistics Table**: Mean, SD, and response distribution for all quantitative items
2. **Construct Score Visualization**: Bar/radar charts for composite scores
3. **Theme Frequency Analysis**: Coded theme counts and representative quotes
4. **Improvement Priority Matrix**: Mapping identified issues to development priorities

---

## Survey Administration

### Distribution Method
- Qualtrics online survey platform
- Anonymous response collection
- Mobile-responsive design

### Timing
- Administered post-system interaction
- Estimated completion time: 10-15 minutes

### Response Validation
- Required responses for core Likert items
- Conditional display for follow-up questions (e.g., Q18 shown only if Q17 ≠ "No")
